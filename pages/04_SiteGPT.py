# test URL
# https://openai.com/index/introducing-gpts/
# https://openai.com/sitemap.xml

# from langchain.document_loaders import AsyncChromiumLoader
# from langchain.document_transformers import Html2TextTransformer #ì™¸ë¶€ packageì§€ë§Œ LangChainì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©
from langchain.document_loaders import SitemapLoader #internally uses BeautifulSoup
from langchain.text_splitter import RecursiveCharacterTextSplitter
import streamlit as st


st.set_page_config(page_title="SiteGPT", page_icon="ğŸŒ")
st.title("SiteGPT")
st.markdown("""
        Welcome to SiteGPT!
            
        test URL : https://openai.com/index/introducing-gpts/

        test URL2: https://openai.com/sitemap.xml
""")

# html2text_transformer = Html2TextTransformer()

def parse_page(soup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header: #soupë¡œë¶€í„° header&footer ì œê±°
        header.decompose()
    if footer:
        footer.decompose()
    return str(soup.get_text()).replace('\n', ' ').replace("\xa0", ' ').replace('CloseSearch Submit Blog', ' ') #ë°˜í™˜ëœ ê°’ì€ page_contentë¡œì„œ documentì— í¬í•¨ë¨

@st.cache_data(show_spinner="Loading website...")
def load_website(url):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200)
    loader = SitemapLoader(
        url, 
        filter_urls=[r"^(.*\/blog\/).*"], #filter_urlsì—ëŠ” íŠ¹ì • urlì„ ë„£ê±°ë‚˜ regexë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ.
                                        # r"^(.*\/blog\/).*"] : ëª¨ë“  blog urlì„ ìŠ¤í¬ë©
                                        # r"^(?!.*\/blog\/).*"] : blogë¥¼ ì œì™¸í•œ ëª¨ë“  urlì„ ìŠ¤í¬ë©
        parsing_function = parse_page() #sitemapì˜ ëª¨ë“  urlì— ëŒ€í•´ ì‹¤í–‰ë¨
    )
    loader.requests_per_second = 1 #openaiì˜ ê²½ìš° 951ê°œì˜ í˜ì´ì§€. ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ 1ì´ˆì— 1ê°œì˜ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë©í•¨. ë³€ê²½ ê°€ëŠ¥.
    docs = loader.load_and_split(text_splitter=splitter) #load() ì•„ë‹ˆë©´ load_and_split()
    return docs
with st.sidebar:
    url = st.text_input("Write down a URL", placeholder="https://example.com")

if url:
    if ".xml" not in url:
        with st.sidebar:
            st.error("Please write down a Sitemap URL.") #sitemapì˜ URLë“¤ì„ êµ¬ê¸€ ë“± í¬ë¡¤ëŸ¬ì˜ ìŠ¤í¬ë©ì„ í—ˆìš©í•´ë†“ì€ ê²ƒë“¤.
    else:
        docs=load_website(url)
        st.write(docs)

    # #async chromium loader. ì™„ì „í•œ browserë¥¼ ì‹¤í–‰ ì¤‘ - ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ
    # loader = AsyncChromiumLoader([url]) #takes a list of urls but we receive only one url
    # docs = loader.load() #list of docs
    # transformed = html2text_transformer.transform_documents(docs)
    # st.write(transformed)


